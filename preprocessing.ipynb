{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2f3ad1e2-e088-4221-8c2a-3e049a6acb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdb4a95-b253-4d0d-9641-a20c4be839e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "data = data[:100]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6414cc15-9a42-441e-a26c-7487e16f1c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float32')\n",
    "\n",
    "plt.figure(figsize=[8, 4])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(data[\"SalaryNormalized\"], bins=20);\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(data['Log1pSalary'], bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2615f360-3cc0-4ce8-99b6-54cab7335558",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_columns = [\"Title\", \"FullDescription\"]\n",
    "\n",
    "categorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \"ContractType\", \"ContractTime\"]\n",
    "\n",
    "TARGET_COLUMN = \"Log1pSalary\"\n",
    "\n",
    "data[categorical_columns] = data[categorical_columns].fillna('NaN')\n",
    "\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625f682e-861d-4380-aae9-d14ad7660691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk import WordPunctTokenizer\n",
    "\n",
    "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "\n",
    "# Will have Title as string of space separated tokens \n",
    "data['Title'] = data['Title'].apply(lambda x: \" \".join((tokenizer.tokenize(str(x).lower()))))\n",
    "# Will have FullDescription as string of space separated tokens \n",
    "data['FullDescription'] = data['FullDescription'].apply(lambda x: \" \".join((tokenizer.tokenize(str(x).lower()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827347df-fb85-48dd-802d-5e0534eb8eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26080806-09c7-4020-a5e8-40ee7e677a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tokens_count = Counter(sum([i.split() for i in data['Title']], []))\n",
    "descr_tokens_count = Counter(sum([i.split() for i in data['FullDescription']], []))\n",
    "\n",
    "tokens_count       = title_tokens_count + descr_tokens_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67664681-4da2-4b2a-af2c-d8af51d5a477",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{len(tokens_count)} unique tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fd1e57-b0e3-432b-91a8-e3bd0c59d966",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_count = 10\n",
    "tokens    = [token for token, count in tokens_count.items() if count > min_count]\n",
    "# Add special tokens for unknown and padding\n",
    "UNK, PAD  = \"UNK\", \"PAD\"\n",
    "tokens    = [UNK, PAD] + tokens\n",
    "\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb10318-788a-4dbb-8fec-640d15803c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Vocabulary size is\", len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c43374b-58a7-44d7-9259-fa6be5c772a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toke index\n",
    "token_to_idx = {token: tokens.index(token) for token in tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899eca0b-79ff-434f-8db9-4c5bc4ff6d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_IX, PAD_IX = map(token_to_idx.get, [UNK, PAD])\n",
    "\n",
    "\n",
    "def as_matrix(sequences):\n",
    "    sequences = list(map(tokenizer.tokenize, sequences))\n",
    "    \n",
    "    max_len = max(map(len, sequences))\n",
    "    \n",
    "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
    "    \n",
    "    for i, seq in enumerate(sequences):\n",
    "        row_idxs = [token_to_idx.get(token, UNK_IX) for token in seq]\n",
    "        matrix[i, :len(row_idxs)] = row_idxs\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d57e62-8279-4248-a7ca-fe9e85899a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "as_matrix(['Hi, I am cat',\n",
    "           'I like data science'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9b15c7-e2f2-4e66-b4bb-2fd7e4327a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "\n",
    "top_k_companies_names, top_k_companies_counts = zip(*Counter(data['Company']).most_common(k))\n",
    "\n",
    "unique_top_k_companies_names = set(top_k_companies_names)\n",
    "\n",
    "data['Company'] = data['Company'].apply(lambda comp: comp if comp in unique_top_k_companies_names else \"Other\")\n",
    "\n",
    "data['Company']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c26a80d-cafd-4436-a7d4-ed7fd3a8fe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "categorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\n",
    "\n",
    "categorical_vectorizer.fit(data[categorical_columns].apply(dict, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c517bcf-8f94-41be-809c-f5cfe9b5bbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_val = train_test_split(data, test_size=0.2, random_state=42)\n",
    "data_train.index     = range(len(data_train))\n",
    "data_val.index       = range(len(data_val))\n",
    "\n",
    "print(\"Train size = \", len(data_train))\n",
    "print(\"Validation size = \", len(data_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e037b99-fd9d-49a1-b314-8de8a9f97bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(data, batch_size, title_word_dropout=0, descr_word_dropout=0):\n",
    "    batch = {}\n",
    "    \n",
    "    batch[\"FullDescription\"] = as_matrix(data[\"FullDescription\"].values)\n",
    "    batch[\"Title\"] = as_matrix(data[\"Title\"].values)\n",
    "    \n",
    "    batch['Categorical'] = categorical_vectorizer.transform(data[categorical_columns].apply(dict, axis=1))\n",
    "    \n",
    "    if title_word_dropout != 0:\n",
    "        batch[\"Title\"] = apply_word_dropout(batch[\"Title\"], keep_prop= 1. - title_word_dropout)\n",
    "    if descr_word_dropout !=0:\n",
    "        batch[\"FullDescription\"] = apply_word_dropout(batch[\"FullDescription\"], keep_prop= 1. - descr_word_dropout)\n",
    "    if TARGET_COLUMN in data.columns:\n",
    "        batch[TARGET_COLUMN] = data[TARGET_COLUMN].values\n",
    "\n",
    "    \n",
    "    return to_tensors(batch)\n",
    "\n",
    "\n",
    "\n",
    "def apply_word_dropout(matrix, keep_prop, replace_with=UNK_IX, pad_ix=PAD_IX,):\n",
    "    \"\"\"\n",
    "    matrix: numpy array, needed to use matrix != pad_ix mask condition\n",
    "    because we dont want to set UNK to the PAD\n",
    "    \"\"\"\n",
    "    dropout_mask = np.random.choice(2, np.shape(matrix), p=[keep_prop, 1 - keep_prop])\n",
    "    dropout_mask &= matrix != pad_ix\n",
    "    return np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])\n",
    "\n",
    "\n",
    "\n",
    "def to_tensors(batch):\n",
    "    batch_tensors = dict()\n",
    "    for key, arr in batch.items():\n",
    "        batch_tensors[key] = torch.tensor(arr)\n",
    "    return batch_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7341638-2d50-4427-81c0-54931b4e240a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_dim=64, n_tokens=len(tokens), n_cat_features=len(categorical_vectorizer.vocabulary_)):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.full_description_emb = nn.Embedding(n_tokens, embedding_dim)\n",
    "        self.title_emb = nn.Embedding(n_tokens, embedding_dim)\n",
    "        \n",
    "        self.full_description_seq = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=embedding_dim, out_channels=16, kernel_size=3, stride=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.title_seq = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=embedding_dim, out_channels=16, kernel_size=3, stride=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.categorical_seq = nn.Linear(in_features=n_cat_features, out_features=16)\n",
    "        \n",
    "        self.final = nn.Linear(in_features=16 * 3, out_features=1)\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        full_description = batch[\"FullDescription\"]\n",
    "        title = batch[\"Title\"]\n",
    "        categorical = batch[\"Categorical\"]\n",
    "        \n",
    "        full_description_emb = self.full_description_emb(full_description).transpose(1, 2)\n",
    "        full_description_output = self.full_description_seq(full_description_emb).mean(dim=2)\n",
    "        \n",
    "        title_emb = self.title_emb(title).transpose(1, 2)\n",
    "        title_output = self.title_seq(title_emb).mean(dim=2)\n",
    "        \n",
    "        categorical_output = self.categorical_seq(categorical)\n",
    "\n",
    "        merged_output = torch.cat([full_description_output, title_output, categorical_output], dim=1)\n",
    "\n",
    "        output = self.final(merged_output).reshape(-1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867cd704-98ad-4259-bcfc-6e94563466d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_minibatches(data, batch_size=256, shuffle=True, device=torch.device('cpu'), **kwargs):\n",
    "    indices = np.arange(len(data))\n",
    "    if shuffle:\n",
    "        indices = np.random.permutation(indices)\n",
    "\n",
    "    for start in range(0, len(indices), batch_size):\n",
    "        batch = make_batch(data.iloc[indices[start : start + batch_size]], batch_size=batch_size, **kwargs)\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c99ed6f-7e09-45d0-907f-eb167027d5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 20\n",
    "DEVICE = torch.device('cpu')\n",
    "\n",
    "\n",
    "def print_metrics(model, data, batch_size=BATCH_SIZE, name=\"\", **kw):\n",
    "    squared_error = abs_error = num_samples = 0.0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in iterate_minibatches(data, batch_size=batch_size, shuffle=False, **kw):\n",
    "            batch_pred = model(batch)\n",
    "            squared_error += torch.sum(torch.square(batch_pred - batch[TARGET_COLUMN]))\n",
    "            abs_error += torch.sum(torch.abs(batch_pred - batch[TARGET_COLUMN]))\n",
    "            num_samples += len(batch_pred)\n",
    "    mse = squared_error.detach().cpu().numpy() / num_samples\n",
    "    mae = abs_error.detach().cpu().numpy() / num_samples\n",
    "    print(\"%s results:\" % (name or \"\"))\n",
    "    print(\"Mean square error: %.5f\" % mse)\n",
    "    print(\"Mean absolute error: %.5f\" % mae)\n",
    "    return mse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9090c63-8a93-445c-93db-8974e1e8e5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model     = Model()\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c8a41f-61bf-4995-918d-d960298b1986",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(f\"epoch: {epoch}\")\n",
    "    model.train()\n",
    "    for i, batch in tqdm.notebook.tqdm(enumerate(\n",
    "            iterate_minibatches(data_train, batch_size=BATCH_SIZE, device=DEVICE)),\n",
    "            total=len(data_train) // BATCH_SIZE\n",
    "        ):\n",
    "        pred = model(batch)\n",
    "        loss = criterion(pred, batch[TARGET_COLUMN])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch % 10 == 0: \n",
    "        print_metrics(model, data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260af998-074d-4882-917a-cb9880f05433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain(model, sample, col_name, sensitivity=1):\n",
    "    sample_col_tokens = [tokens[token_to_idx.get(tok, 0)] for tok in sample[col_name].split()]\n",
    "\n",
    "    data_drop_one_token = pd.DataFrame([sample] * (len(sample_col_tokens)))\n",
    "    data_full           = pd.DataFrame([sample] * (len(sample_col_tokens)))\n",
    "\n",
    "    # Since we want to try to drop each word we will have\n",
    "    # to set 'number of words' times UNC to different position\n",
    "    batch_size = len(data_full)\n",
    "\n",
    "    text_col_idx = data_full.columns.get_loc(col_name)\n",
    "    text = data_drop_one_token.iloc[0, text_col_idx].split()\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        data_drop_one_token.iloc[i, text_col_idx] = ' '.join([UNK if j == i else t for j, t in enumerate(text)])\n",
    "\n",
    "    data_drop_one_token_batch  = make_batch(data_drop_one_token, batch_size)\n",
    "    data_drop_one_token_output = model.forward(data_drop_one_token_batch)\n",
    "\n",
    "\n",
    "    data_baseline_batch = make_batch(data_full, batch_size)\n",
    "    data_baseline = model.forward(data_baseline_batch)\n",
    "\n",
    "    # if diff < 0 it means that without word, the price is higher,\n",
    "    # so probably its red flag, lets make it red\n",
    "    # and if diff > 0 it means that without price is lower\n",
    "    diff = (data_baseline - data_drop_one_token_output).detach() * sensitivity\n",
    "    return list(zip(text, diff))\n",
    "    \n",
    "# explain(model=model, sample=data.iloc[2], col_name='Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4962cb91-9e0e-40b4-a154-254e799bf223",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display_html\n",
    "\n",
    "\n",
    "def draw_html(tokens_and_weights, cmap=plt.get_cmap(\"bwr\"), display=True,\n",
    "              token_template=\"\"\"<span style=\"background-color: {color_hex}\">{token}</span>\"\"\",\n",
    "              font_style=\"font-size:14px;\"):\n",
    "    \n",
    "    def get_color_hex(weight):\n",
    "        # weight here is out diff so when its < 0 then it means without this word\n",
    "        # price would be higher so its reg flag to delete\n",
    "        # Sigmoid kind of\n",
    "        rgba = cmap(1. / (1 + np.exp(weight.detach().numpy())), bytes=True)\n",
    "        return '#%02X%02X%02X' % rgba[:3]\n",
    "    \n",
    "    tokens_html = [\n",
    "        token_template.format(token=token, color_hex=get_color_hex(weight))\n",
    "        for token, weight in tokens_and_weights\n",
    "    ]\n",
    "    \n",
    "    raw_html = \"\"\"<p style=\"{}\">{}</p>\"\"\".format(font_style, ' '.join(tokens_html))\n",
    "    if display:\n",
    "        display_html(HTML(raw_html))\n",
    "        \n",
    "    return raw_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b79463-7b0c-4564-a8b5-ff3186a2dddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_title = explain(model=model, sensitivity=1, sample=data.iloc[23], col_name='Title')\n",
    "draw_html([(text, diff) for text, diff in explain_title]);\n",
    "\n",
    "explain_descr = explain(model=model, sensitivity=10, sample=data.iloc[23], col_name='FullDescription')\n",
    "draw_html([(text, diff) for text, diff in explain_descr]);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
